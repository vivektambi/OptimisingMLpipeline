# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about potential customers of a bank and their loan and finalcial history records. 
In our problem statement, we seek to predict weather an individual is an ideal candidate for our marketing campaign.

The best performing model was Python-SDK and Azure Hyperdrive with accuracy of 91.01%. Azure AutoML also performed well with slightly less accuracy of 88.9 %

## Scikit-learn Pipeline
Pipeline Architecture: 
  Data: The data used is bank-marketing data. It is a list of bank-customers along with their information(features) such as loans, gender, marital_status, education etc.
Final number of features after data cleaning and creating dummy variables from given categorical variables is 39. Target variable is "y"; It is a binary variable signifying sucess(1) and failure(0).

  Classification Algorithm: 
  Clearly, this is a classification problem. The model used for the Python SDK experiment is a Logistic Regression. It is one of the most basic and powerful algorithms for     classification problems in machine learning.

  Hyperparameter tuning:
  Two hyperparameters were tuned for training:
  1. C: Inverse of regularisation strength. Decresing value signifies greater regularisation strength.
  This value must always be positive ( default=1). For our tuning, we used uniform(min,max) which specifies a uniform distribution between min and max values from which random values are chosen.
  2. max_iter: this specifies the maximum number of iterations that the logistic regression model will run before arriving at the best possible set of hyperparameters. 
The program creates several combinations of these two hyperparameters. Then each of these combinations runs until the end or until the termination policy holds True. 

Among the random sampler and the grid sampler, I have chosen the random sampler for this dataset. 
The main reason for choosing random sampler in this case is that it randomly selects a few combinations of parameter settings allowing us to save time and resource cost for training the model with little differnece in accuracy. It gives support for both continuous and discrete hyperparameters.

From among three early stopping policies available in azureML library, I chose the Bandit policy for early termination. This policy utlizes the slack_factor to terminate the program early. Slack factor is the ratio used to calculate the allowed distance from best performing experiment run.

## AutoML
The best model generated by AutoML in azure was LightGBM with a accuracy score of 88.9%.
TO get a detailed understanding of the hyperparamters and their significance in the modelling process, you can refer to the official documentation
https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html

![alt text](https://github.com/vivektambi/OptimisingMLpipeline/pipeline.PNG?raw=true)

## Pipeline comparison
Accuracy metric obtained via HyperDrive is better than AutoML. Logistic Regression Hyper-drive performed better than autoML by almost 1 percentage point.
Hyperdrive is an exaustive comparison between individual models run on combinations of hyperparameters and then selecting the hyperparameter combination that gives the best performance metric( in our case -- accuracy).
AutoML is a comparison of different techniques and selects the best technique with best set of hyperparameters that gives the best performance metric.
There is a difference in accuracy due to the hyperparameter settings provided by me in the hyperparameter_config. 

## Future work
Future imrovements: 
  1. For goal_metric, AUC is another very important metric to measure model performance. Evaluating model performance with this metric and maximising this in hyperdrive runs as well as auto-ml runs will give new insights into the model.
